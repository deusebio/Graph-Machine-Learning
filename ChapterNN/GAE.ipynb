{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64a3e76b-18a0-4b30-8840-3c491b5aae5f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94acb909-b6cc-4e4e-8f44-59552fc6a84b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "448f877a-dcfa-4261-8d83-1175facdfc93",
   "metadata": {},
   "source": [
    "networkx\n",
    "tensorflow\n",
    "scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6b698a93-e89b-4819-9ef9-586d544a243a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4826e139-b742-454b-932f-72d61a7d49f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-10 00:57:23.168965: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-10 00:57:23.170593: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-03-10 00:57:23.201193: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-03-10 00:57:23.201956: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-03-10 00:57:23.766842: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import keras \n",
    "import os\n",
    "\n",
    "zip_file = keras.utils.get_file(\n",
    "    fname=\"cora.tgz\",\n",
    "    origin=\"https://linqs-data.soe.ucsc.edu/public/lbc/cora.tgz\",\n",
    "    extract=True,\n",
    ")\n",
    "data_dir = os.path.join(os.path.dirname(zip_file), \"cora\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2391ee29-37d6-40e3-9ab6-99d8c3d04101",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Citations shape: (5429, 2)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "citations = pd.read_csv(\n",
    "    os.path.join(data_dir, \"cora.cites\"),\n",
    "    sep=\"\\t\",\n",
    "    header=None,\n",
    "    names=[\"target\", \"source\"],\n",
    ")\n",
    "print(\"Citations shape:\", citations.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4682e143-d23d-43d7-a912-51b6b8194a1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>35</td>\n",
       "      <td>1033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>35</td>\n",
       "      <td>103482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>35</td>\n",
       "      <td>103515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>35</td>\n",
       "      <td>1050679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35</td>\n",
       "      <td>1103960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5424</th>\n",
       "      <td>853116</td>\n",
       "      <td>19621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5425</th>\n",
       "      <td>853116</td>\n",
       "      <td>853155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5426</th>\n",
       "      <td>853118</td>\n",
       "      <td>1140289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5427</th>\n",
       "      <td>853155</td>\n",
       "      <td>853118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5428</th>\n",
       "      <td>954315</td>\n",
       "      <td>1155073</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5429 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      target   source\n",
       "0         35     1033\n",
       "1         35   103482\n",
       "2         35   103515\n",
       "3         35  1050679\n",
       "4         35  1103960\n",
       "...      ...      ...\n",
       "5424  853116    19621\n",
       "5425  853116   853155\n",
       "5426  853118  1140289\n",
       "5427  853155   853118\n",
       "5428  954315  1155073\n",
       "\n",
       "[5429 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "citations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9136ca0e-d8a5-43ba-b72c-606ec85d44ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Papers shape: (2708, 1435)\n"
     ]
    }
   ],
   "source": [
    "column_names = [\"paper_id\"] + [f\"term_{idx}\" for idx in range(1433)] + [\"subject\"]\n",
    "papers = pd.read_csv(\n",
    "    os.path.join(data_dir, \"cora.content\"), sep=\"\\t\", header=None, names=column_names,\n",
    ")\n",
    "print(\"Papers shape:\", papers.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e9bdf58e-bb7f-43e3-a3cd-bd699d4f0c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_values = sorted(papers[\"subject\"].unique())\n",
    "class_idx = {name: id for id, name in enumerate(class_values)}\n",
    "paper_idx = {name: idx for idx, name in enumerate(sorted(papers[\"paper_id\"].unique()))}\n",
    "\n",
    "papers[\"paper_id\"] = papers[\"paper_id\"].apply(lambda name: paper_idx[name])\n",
    "citations[\"source\"] = citations[\"source\"].apply(lambda name: paper_idx[name])\n",
    "citations[\"target\"] = citations[\"target\"].apply(lambda name: paper_idx[name])\n",
    "papers[\"subject\"] = papers[\"subject\"].apply(lambda value: class_idx[value])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "99f113f6-b3e9-41c5-a6ee-873536c599bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paper_id</th>\n",
       "      <th>term_0</th>\n",
       "      <th>term_1</th>\n",
       "      <th>term_2</th>\n",
       "      <th>term_3</th>\n",
       "      <th>term_4</th>\n",
       "      <th>term_5</th>\n",
       "      <th>term_6</th>\n",
       "      <th>term_7</th>\n",
       "      <th>term_8</th>\n",
       "      <th>...</th>\n",
       "      <th>term_1424</th>\n",
       "      <th>term_1425</th>\n",
       "      <th>term_1426</th>\n",
       "      <th>term_1427</th>\n",
       "      <th>term_1428</th>\n",
       "      <th>term_1429</th>\n",
       "      <th>term_1430</th>\n",
       "      <th>term_1431</th>\n",
       "      <th>term_1432</th>\n",
       "      <th>subject</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>462</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1911</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2002</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>248</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>519</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2703</th>\n",
       "      <td>2370</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2704</th>\n",
       "      <td>2371</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2705</th>\n",
       "      <td>2372</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2706</th>\n",
       "      <td>955</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2707</th>\n",
       "      <td>376</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2708 rows × 1435 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      paper_id  term_0  term_1  term_2  term_3  term_4  term_5  term_6  \\\n",
       "0          462       0       0       0       0       0       0       0   \n",
       "1         1911       0       0       0       0       0       0       0   \n",
       "2         2002       0       0       0       0       0       0       0   \n",
       "3          248       0       0       0       0       0       0       0   \n",
       "4          519       0       0       0       0       0       0       0   \n",
       "...        ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "2703      2370       0       0       0       0       0       0       0   \n",
       "2704      2371       0       0       0       0       0       0       0   \n",
       "2705      2372       0       0       0       0       0       0       0   \n",
       "2706       955       0       0       0       0       1       0       0   \n",
       "2707       376       0       0       0       0       0       0       0   \n",
       "\n",
       "      term_7  term_8  ...  term_1424  term_1425  term_1426  term_1427  \\\n",
       "0          0       0  ...          0          0          1          0   \n",
       "1          0       0  ...          0          1          0          0   \n",
       "2          0       0  ...          0          0          0          0   \n",
       "3          0       0  ...          0          0          0          0   \n",
       "4          0       0  ...          0          0          0          0   \n",
       "...      ...     ...  ...        ...        ...        ...        ...   \n",
       "2703       0       0  ...          0          0          0          0   \n",
       "2704       0       0  ...          0          0          0          0   \n",
       "2705       0       0  ...          0          0          0          0   \n",
       "2706       0       0  ...          0          0          0          0   \n",
       "2707       0       0  ...          0          0          0          0   \n",
       "\n",
       "      term_1428  term_1429  term_1430  term_1431  term_1432  subject  \n",
       "0             0          0          0          0          0        2  \n",
       "1             0          0          0          0          0        5  \n",
       "2             0          0          0          0          0        4  \n",
       "3             0          0          0          0          0        4  \n",
       "4             0          0          0          0          0        3  \n",
       "...         ...        ...        ...        ...        ...      ...  \n",
       "2703          0          0          0          0          0        1  \n",
       "2704          0          0          0          0          0        1  \n",
       "2705          0          0          0          0          0        1  \n",
       "2706          0          0          0          0          0        0  \n",
       "2707          0          0          0          0          0        2  \n",
       "\n",
       "[2708 rows x 1435 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "papers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "77fc40eb-a7a1-4293-90fb-4b4e70bc6d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "cora_graph = nx.from_pandas_edgelist(citations.sample(n=1500))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c720e6a1-5edb-4df9-ab3e-c2e4e219e550",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NodeView((2047, 996, 341, 236, 140, 355, 1621, 747, 2290, 464, 2121, 121, 370, 371, 2299, 604, 2168, 781, 1901, 87, 2150, 108, 2575, 333, 1865, 1559, 2441, 1703, 2403, 20, 198, 1102, 1930, 270, 1916, 1081, 65, 286, 1476, 149, 368, 122, 2357, 71, 1247, 15, 2597, 749, 2294, 49, 1909, 504, 1983, 742, 2677, 1582, 861, 703, 2684, 1664, 2443, 1708, 220, 230, 2278, 385, 312, 27, 2631, 549, 2370, 1066, 1536, 1537, 936, 411, 227, 226, 301, 3, 2177, 416, 444, 197, 2226, 1162, 1672, 1210, 1173, 351, 613, 173, 2046, 415, 995, 1040, 1731, 1722, 244, 455, 1525, 1112, 627, 728, 1766, 686, 2069, 1009, 251, 2174, 394, 1265, 50, 1789, 1398, 1609, 576, 838, 1727, 348, 1357, 2198, 1392, 2061, 434, 2243, 823, 1122, 237, 177, 2702, 0, 2249, 878, 2375, 399, 710, 222, 1151, 1150, 90, 200, 841, 2615, 453, 388, 340, 1592, 585, 484, 792, 1012, 101, 1362, 13, 326, 1871, 1872, 791, 485, 1576, 1580, 1195, 2025, 165, 860, 2541, 33, 171, 397, 2277, 448, 1219, 495, 556, 367, 373, 47, 109, 2104, 894, 414, 2, 1601, 780, 582, 1275, 2105, 1088, 2395, 470, 2591, 252, 110, 1782, 601, 569, 1569, 1556, 992, 653, 2240, 174, 2073, 1057, 1640, 524, 1936, 377, 1854, 402, 2341, 669, 207, 208, 2200, 1810, 1554, 2281, 45, 2469, 1368, 1945, 502, 1197, 379, 885, 1390, 532, 353, 2353, 1349, 1404, 1035, 1915, 12, 2255, 921, 2613, 784, 736, 1323, 1750, 1746, 2523, 817, 1720, 1713, 2397, 814, 28, 1185, 111, 1363, 520, 64, 57, 1058, 837, 11, 713, 643, 2705, 1262, 1064, 2617, 1105, 231, 961, 959, 1063, 523, 179, 490, 763, 274, 1420, 527, 2500, 1779, 147, 1364, 2273, 1526, 1594, 1961, 395, 999, 60, 170, 93, 9, 501, 390, 2698, 507, 851, 2385, 2620, 1317, 2405, 1657, 1805, 472, 755, 1571, 1570, 2166, 68, 2564, 161, 247, 424, 1967, 509, 151, 1401, 1496, 62, 1755, 1756, 1396, 238, 54, 954, 1562, 881, 2587, 973, 2675, 384, 1963, 651, 538, 2364, 1600, 1977, 718, 72, 535, 357, 204, 2654, 796, 1812, 1011, 1850, 85, 2003, 1899, 681, 421, 655, 1244, 282, 1446, 1679, 295, 639, 153, 661, 2706, 176, 1075, 219, 1256, 1257, 1351, 1846, 1136, 498, 2011, 2401, 919, 593, 1567, 1497, 1019, 2219, 734, 225, 1460, 1344, 1564, 882, 1960, 635, 1472, 1069, 1498, 229, 2470, 1502, 2129, 1284, 2531, 1768, 2660, 760, 2636, 719, 403, 630, 1264, 1135, 48, 1289, 1192, 1003, 1090, 1578, 52, 2333, 1103, 2051, 1018, 1738, 1736, 809, 1188, 915, 1041, 927, 2369, 1794, 1793, 1397, 559, 1619, 1165, 1530, 1385, 158, 1596, 1841, 828, 202, 2019, 154, 897, 2289, 124, 638, 512, 409, 429, 893, 1940, 488, 2453, 574, 2481, 829, 310, 1356, 44, 1201, 2508, 1787, 1604, 1602, 2606, 266, 2568, 1845, 2006, 531, 16, 1761, 2457, 1042, 2041, 708, 169, 168, 2639, 810, 59, 1825, 543, 1689, 1608, 657, 2417, 205, 104, 1521, 1522, 1641, 1566, 1709, 913, 213, 216, 2321, 1523, 514, 7, 2555, 1844, 1769, 1873, 1052, 712, 1399, 102, 77, 1414, 1272, 1922, 107, 467, 1686, 1375, 926, 2049, 503, 766, 46, 864, 1155, 74, 1654, 1470, 84, 1120, 22, 23, 2612, 583, 2673, 1138, 1276, 1651, 259, 904, 773, 255, 254, 511, 2525, 834, 446, 1883, 1665, 126, 807, 1045, 383, 211, 1014, 602, 2217, 374, 224, 1610, 1986, 578, 1031, 89, 1980, 316, 757, 363, 496, 1827, 1053, 391, 223, 1627, 644, 335, 2076, 1747, 1211, 439, 1047, 1145, 1250, 187, 67, 117, 1529, 2338, 2235, 1115, 2114, 1059, 1437, 1096, 1931, 275, 647, 1017, 235, 294, 1291, 405, 492, 832, 2374, 1246, 2699, 2093, 142, 695, 883, 756, 269, 550, 2125, 1278, 1072, 2560, 1692, 1843, 1253, 31, 127, 328, 799, 1822, 136, 536, 1191, 2594, 1914, 924, 525, 1241, 1050, 975, 2462, 1726, 366, 833, 1962, 646, 900, 192, 1441, 1451, 677, 2656, 869, 95, 1295, 193, 1126, 2300, 941, 1252, 1572, 2124, 1189, 1994, 801, 1969, 240, 1754, 2039, 812, 1180, 577, 2649, 1319, 804, 805, 624, 626, 2489, 1771, 1060, 25, 438, 2167, 347, 217, 637, 324, 323, 2379, 1633, 1043, 1642, 1217, 1187, 2664, 184, 2428, 1688, 1346, 1808, 1740, 1706, 2081, 78, 2583, 1422, 1056, 1800, 408, 2118, 2242, 195, 824, 2376, 1240, 1098, 1374, 530, 667, 1492, 143, 1371, 1991, 30, 486, 2100, 1216, 597, 596, 854, 152, 313, 487, 2181, 700, 1760, 672, 1030, 1445, 234, 2126, 555, 696, 305, 2292, 982, 2422, 1678, 2486, 1656, 91, 2482, 2645, 42, 1503, 1022, 119, 2252, 1506, 1763, 1358, 733, 1330, 291, 1505, 720, 1320, 2423, 103, 1589, 2406, 917, 707, 568, 160, 2678, 1254, 2098, 337, 289, 566, 2473, 1829, 758, 2506, 929, 61, 63, 100, 2207, 546, 380, 1434, 997, 1473, 287, 911, 988, 1085, 526, 586, 972, 1712, 2424, 1051, 1867, 1866, 1198, 420, 1923, 137, 1220, 1413, 469, 1944, 279, 2692, 1207, 2301, 1270, 846, 432, 1077, 1546, 1296, 1083, 822, 1748, 649, 1215, 1402, 1336, 1717, 1204, 2102, 1222, 2697, 141, 1990, 1975, 2024, 744, 2156, 730, 331, 2644, 2637, 118, 923, 2186, 1767, 1528, 714, 228, 2490, 786, 1809, 1301, 55, 845, 1406, 79, 2561, 690, 115, 745, 2163, 243, 1158, 1995, 2074, 1993, 2432, 2202, 1023, 874, 1583, 949, 2532, 584, 131, 14, 253, 618, 2182, 1263, 5, 114, 481, 1299, 1673, 393, 600, 459, 1906, 872, 1271, 2086, 83, 1178, 6, 944, 2365, 1585, 1026, 1024, 2681, 2205, 839, 1161, 2203, 417, 2142, 664, 1561, 271, 980, 560, 26, 1818, 278, 471, 1260, 1261, 557, 795, 241, 930, 1581, 1587, 2134, 361, 2611, 579, 2504, 1780, 1860, 186, 2313, 2558, 1617, 1613, 2474, 1762, 1172, 816, 2151, 2002, 2171, 1558, 2022, 2576, 1863, 2091, 1181, 702, 1338, 292, 293, 1920, 1293, 517, 1982, 1474, 298, 971, 738, 737, 540, 724, 715, 2316, 297, 1196, 166, 1932, 2267, 552, 2410, 128, 1979, 1380, 614, 1412, 1224, 684, 2348, 352, 1367, 1423, 603, 1028, 652, 2399, 290, 2218, 1415, 2421, 1442, 2518, 1786, 1061, 852, 2608, 513, 317, 1106, 2600, 1949, 931, 1616, 940, 2402, 717, 1279, 2344, 413, 375, 2412, 196, 1440, 1785, 1174, 156, 2581, 539, 858, 1743, 1742, 2623, 1146, 2502, 1700, 2131, 521, 516, 2603, 2634, 1381, 537, 1461, 1970, 683, 890, 144, 2429, 123, 1039, 1702, 1280, 993, 2162, 1588, 2582, 2538, 711, 75, 303, 886, 381, 675, 1432, 132, 859, 80, 17, 2543, 751, 1626, 2068, 2435, 106, 1049, 2115, 460, 1143, 701, 1698, 1067, 945, 1142, 612, 2371, 1494, 2071, 1116, 499, 214, 1997, 765, 2537, 1171, 58, 1548, 551, 494, 1471, 433, 135, 1544, 1514, 1513, 764, 2119, 76, 1408, 428, 1184, 1182, 774, 1000, 189, 506, 280, 2368, 656, 922, 1175, 2463, 1744, 1733, 1734, 811, 1902, 966, 1676, 1370, 589, 2567, 1857, 2347, 2244, 779, 339, 1879, 1303, 2632, 296, 1236, 541, 642, 2033, 2657, 2578, 1563, 660, 662, 946, 518, 250, 249, 1875, 2454, 53, 1799, 407, 2420, 1200, 2691, 2351, 2026, 2138, 843, 1350, 1778, 868, 1848, 2511, 2685, 1828, 1685, 1684, 2185, 1389, 617, 304, 991, 790, 2246, 452, 2336, 906, 2065, 378, 2633, 1326, 2659, 40, 1690, 2627, 682, 1444, 233, 1882, 1486, 1531, 2283, 1524, 2679, 1065, 666, 427, 1859, 515, 1170, 450, 508, 1788, 1791, 2133, 376, 113, 2317, 354, 2468, 2176, 688, 2638, 1591, 732, 203, 120, 436, 1400, 1824, 1687, 194, 1015, 1016, 2066, 1110, 1683, 1770, 2571, 1858, 709, 182, 2590, 410, 2586, 563, 976, 842, 2173, 350, 2411, 1662, 1577, 497, 265, 1612, 857, 916, 191, 716, 1898, 69, 619, 2326, 1540, 989, 1337, 2057, 1, 2261, 698, 2400, 1900, 2032, 167, 956, 548, 2360, 1598, 968, 148, 2279, 1226, 1707, 865, 605, 1484, 1815, 1942, 1327, 1431, 676, 1084, 1934, 1757, 2650, 1624, 1623, 2635, 977, 2238, 1328, 562, 2268, 1407, 2467, 2372, 1605, 2602, 654, 392, 1314, 908, 1924, 180, 571, 262, 330, 1881, 245, 2067, 461, 668, 1286, 1517, 1209, 474, 1935, 2023, 1212, 740, 2529, 827, 2140, 188, 2658, 473, 2461, 844, 2236, 273, 2095, 2000, 772, 2206, 334, 1697, 2695, 212, 1038, 468, 725, 937, 902, 2643, 594, 2668, 365, 1027, 2087, 2269, 866, 435, 2079, 1227, 1159, 1205, 1516, 979, 483, 1870, 813, 1214, 2436, 1550, 302, 1817, 150, 1156, 431, 1821, 1231, 547, 2089, 2452, 1725, 1819, 1551, 1290, 1888, 1832, 2088, 1157, 1953, 570, 1560, 2380, 1379, 479, 1987, 1491, 2535, 1823, 1427, 1718, 1007, 2284, 2334, 342, 332, 789, 1628, 1611, 1304, 1999, 1903, 1082, 609, 1183, 1509, 398, 1132, 1861, 1784, 1485, 2599, 1225, 465, 1372, 284, 2625, 2123, 1086, 2544, 404, 1893, 1826, 1168, 1111, 2425, 1329, 1458, 1478, 288, 2478, 1765, 2476, 640, 336, 1968, 1169, 2209, 2318, 533, 146, 1749, 825, 2028, 1897, 2595, 1998, 73, 1553, 572, 794, 1966, 1599, 138, 1855, 164, 2661, 327, 1373, 2416, 1939, 820, 2149, 1277, 1868, 1555, 478, 2680, 1403, 2330, 1545, 939, 2232, 51, 2128, 1267, 2700, 863, 2539, 607, 798, 1579, 2387, 2450, 1449, 1190, 1634, 1287, 694, 1721, 1315, 2083, 648, 2689, 1777, 1318, 1847, 1910, 441, 1723, 920, 2179, 1034, 178, 1918, 260, 2144, 1306, 2359, 1108, 2704, 2245, 529, 43, 2106, 1745, 1533, 1691, 2072, 242, 692, 1199, 1332, 1391, 884, 482, 2346, 706, 2642, 581, 2609, 761, 358, 2345, 1584, 1639, 2175, 2250, 96, 2437, 1699, 2554, 2077, 948, 2275, 1904, 221, 209, 2433, 2204, 1097, 658, 2092, 689, 2580, 1869, 489, 423, 953, 257, 2276, 2329, 1543, 1405, 625, 1456, 1715, 1331, 1705, 2439, 360, 2158, 129, 2143, 1693, 1710, 37, 406, 41, 246, 2145, 130, 2195, 1534, 519, 2378, 445, 1783, 2282, 2607, 418, 2257, 400, 1334, 1921, 92, 1001, 2013, 1395, 1501, 325, 955, 430, 364, 1292, 94, 493, 2409, 1661, 2464, 2445, 663, 1452, 1454, 1643, 818, 1958, 1840, 1964, 1100, 285, 2480, 1193, 329, 775, 18, 218, 673, 2393, 447, 2058, 1508, 2038, 947, 1361, 1943, 1758, 2297, 2641, 258, 2152, 1615, 97, 831, 665, 1435, 1792, 2522, 925, 1552, 201, 1411, 943, 2034, 2381, 1635, 2042, 2055))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cora_graph.nodes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cf3899f3-5b2e-46ed-851d-a85e0ad0326b",
   "metadata": {},
   "outputs": [],
   "source": [
    "G=cora_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6e203133-6fbd-4e90-852f-1aa53f5f4cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "adj = (1.0 * (nx.adjacency_matrix(G)>0)).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d81852f1-e294-4272-9546-b8b92028d1cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1f56b228-6596-4e0a-9e0e-da9ae9ea4d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K \n",
    "from keras.layers import Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ac74c638-a758-4920-a18b-75687264c144",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import cached_property\n",
    "\n",
    "class GraphConvolution(Layer):\n",
    "    \"\"\"Basic graph convolution layer for undirected graph without edge labels.\"\"\"\n",
    "    \n",
    "    def __init__(self, output_dim, graph, activation, **kwargs):    \n",
    "        self.output_dim = output_dim \n",
    "        self.graph = graph\n",
    "        self.activation = activation\n",
    "        super(GraphConvolution, self).__init__(**kwargs)\n",
    "\n",
    "    @staticmethod\n",
    "    def preprocess_graph(adj):\n",
    "        adj_ = adj + np.eye(adj.shape[0])\n",
    "        \n",
    "        degree = np.array(adj_.sum(1))\n",
    "        \n",
    "        degree_mat_inv_sqrt = np.diag(np.power(degree, -0.5).flatten())\n",
    "        adj_normalized = adj_.dot(degree_mat_inv_sqrt).transpose().dot(degree_mat_inv_sqrt)\n",
    "    \n",
    "        return adj_normalized\n",
    "\n",
    "    \n",
    "    @cached_property\n",
    "    def adj(self):\n",
    "        return (1.0 * (nx.adjacency_matrix(self.graph)>0)).toarray()\n",
    "    \n",
    "    def build(self, input_shape): \n",
    "        self.w = self.add_weight(\n",
    "            name = 'w', \n",
    "            shape = (input_shape[1], self.output_dim), \n",
    "            initializer = 'normal', trainable = True\n",
    "        ) \n",
    "        self._adj = tf.constant(self.preprocess_graph(self.adj), shape=self.adj.shape, dtype=np.float32)\n",
    "        super(GraphConvolution, self).build(input_shape)\n",
    "\n",
    "    def call(self, input_data): \n",
    "        x = K.dot(input_data, self.w)\n",
    "        x = K.dot(self._adj, x) \n",
    "        return self.activation(x)\n",
    "    \n",
    "    def compute_output_shape(self, input_shape): \n",
    "        return (input_shape[0], self.output_dim)\n",
    "\n",
    "class InnerProductDecoder(Layer):\n",
    "    \"\"\"Decoder model layer for link prediction.\"\"\"\n",
    "\n",
    "    def __init__(self, **kwargs):    \n",
    "        self.activation = tf.nn.sigmoid\n",
    "        super(InnerProductDecoder, self).__init__(**kwargs)\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        x = tf.transpose(inputs)\n",
    "        x = tf.matmul(inputs, x)\n",
    "        # x = tf.reshape(x, [-1])\n",
    "        return self.activation(x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "60d07cde-ca32-447b-a7a2-d2555145995c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b35bf403-e13c-4737-82e9-e93d63807bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import Input, Model\n",
    "\n",
    "n = len(G.nodes())\n",
    "\n",
    "input_img = Input(shape=(n), batch_size=n) \n",
    "\n",
    "hidden = GraphConvolution(10, G, activation=tf.nn.relu)(input_img)\n",
    "embedding = GraphConvolution(2, G, activation=tf.nn.relu)(hidden)\n",
    "\n",
    "reconstructed = InnerProductDecoder()(embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2526f174-272a-4539-bd92-28f2a223404c",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Model(input_img, embedding)\n",
    "\n",
    "model = Model(input_img, reconstructed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e2034e03-e0bf-4b51-ba8d-a6e71840afb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(1660, 1660)]            0         \n",
      "                                                                 \n",
      " graph_convolution (GraphCo  (1660, 10)                16600     \n",
      " nvolution)                                                      \n",
      "                                                                 \n",
      " graph_convolution_1 (Graph  (1660, 2)                 20        \n",
      " Convolution)                                                    \n",
      "                                                                 \n",
      " inner_product_decoder (Inn  (1660, 1660)              0         \n",
      " erProductDecoder)                                               \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 16620 (64.92 KB)\n",
      "Trainable params: 16620 (64.92 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22d4544e-d0cb-4f6b-9e62-91c842ad0316",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "32cbba17-79c8-4a99-80b5-6ab2ea174d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9defa7df-0e1f-4845-a4d3-aa16f4040258",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.eye(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "87da59a8-3ef5-4217-9d48-7c116df1ff3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = adj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "23d1151f-8a5c-498a-9ef7-6a63f9f62d1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 257ms/step - loss: 0.6931\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6931\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.6931\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6931\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6931\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6931\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.6931\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6931\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6931\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.6931\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.6931\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.6931\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6931\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.6931\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.6931\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.6931\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6931\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6931\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.6931\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.6931\n"
     ]
    }
   ],
   "source": [
    "for _ in range(20):\n",
    "    model.fit(x_train, y_train, batch_size=n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "60eada40-4cd2-4f2b-acfa-7cbc2191cb7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = encoder(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "09bd37d3-db11-4c05-b5d8-caf2a46003bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1660, 2), dtype=float32, numpy=\n",
       "array([[0.        , 0.        ],\n",
       "       [0.        , 0.        ],\n",
       "       [0.        , 0.        ],\n",
       "       ...,\n",
       "       [0.00156295, 0.        ],\n",
       "       [0.        , 0.        ],\n",
       "       [0.00103919, 0.        ]], dtype=float32)>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "18517bc8-bf62-4580-a7e8-2df47a956d02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " graph_convolution_9 (Graph  (34, 10)                  340       \n",
      " Convolution)                                                    \n",
      "                                                                 \n",
      " graph_convolution_10 (Grap  (34, 4)                   40        \n",
      " hConvolution)                                                   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 380 (1.48 KB)\n",
      "Trainable params: 380 (1.48 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "60a7ebb9-97ca-4e26-b4d6-493b29bdd6bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(G.nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05dbbce6-3411-4d9f-9672-678a68df86d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0864159-6280-4e8c-8efc-31c280eaad1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "    def __init__(self, input_dim, output_dim, adj, dropout=0., act=tf.nn.relu):\n",
    "        self.dropout = dropout\n",
    "        self.adj = adj\n",
    "        self.act = act\n",
    "\n",
    "    def _call(self, inputs):\n",
    "        x = inputs\n",
    "        x = tf.nn.dropout(x, 1-self.dropout)\n",
    "        x = tf.matmul(x, self.vars['weights'])\n",
    "        x = tf.sparse_tensor_dense_matmul(self.adj, x)\n",
    "        outputs = self.act(x)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45a82e05-1059-4f87-bbd2-b27e774e1966",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "graph-machine-learning",
   "language": "python",
   "name": "graph-machine-learning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
